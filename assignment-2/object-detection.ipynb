{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pprint\n",
    "import tempfile\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from PIL import Image\n",
    "from six import BytesIO\n",
    "from IPython import display\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow_models as tfm\n",
    "# import orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.ops.preprocess_ops import normalize_image\n",
    "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tfm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "with Image.open('./dataset/Object_Detection/coco/train/100002.jpg') as img :\n",
    "    pprint.pprint(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-29 08:16:59.059669: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-29 08:16:59.059897: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 08:16:59.063140: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 08:16:59.113533: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 08:17:00.488852: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-29 08:17:02.849571: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-29 08:17:02.878780: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "I0429 08:17:02.879010 127289934874432 create_coco_tf_record.py:502] writing to output path: ./dataset/Object_Detection/coco_tfrecords/train\n",
      "I0429 08:17:03.184427 127289934874432 create_coco_tf_record.py:374] Building bounding box index.\n",
      "I0429 08:17:03.186138 127289934874432 create_coco_tf_record.py:385] 8 images are missing bboxes.\n",
      "I0429 08:17:04.613395 127289934874432 tfrecord_lib.py:168] On image 0\n",
      "I0429 08:17:04.651881 127289934874432 tfrecord_lib.py:168] On image 100\n",
      "I0429 08:17:04.689992 127289934874432 tfrecord_lib.py:168] On image 200\n",
      "I0429 08:17:04.734262 127289934874432 tfrecord_lib.py:168] On image 300\n",
      "I0429 08:17:04.766394 127289934874432 tfrecord_lib.py:168] On image 400\n",
      "I0429 08:17:04.800892 127289934874432 tfrecord_lib.py:168] On image 500\n",
      "I0429 08:17:04.833863 127289934874432 tfrecord_lib.py:168] On image 600\n",
      "I0429 08:17:04.866147 127289934874432 tfrecord_lib.py:168] On image 700\n",
      "I0429 08:17:04.901740 127289934874432 tfrecord_lib.py:168] On image 800\n",
      "I0429 08:17:04.938799 127289934874432 tfrecord_lib.py:168] On image 900\n",
      "I0429 08:17:04.978920 127289934874432 tfrecord_lib.py:168] On image 1000\n",
      "I0429 08:17:05.014882 127289934874432 tfrecord_lib.py:180] Finished writing, skipped 0 annotations.\n",
      "I0429 08:17:05.021886 127289934874432 create_coco_tf_record.py:537] Finished writing, skipped 0 annotations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN_DATA_DIR='./dataset/Object_Detection/coco/train'\n",
    "TRAIN_ANNOTATION_FILE_DIR='./dataset/Object_Detection/coco/train/train_annotations.json'\n",
    "OUTPUT_TFRECORD_TRAIN='./dataset/Object_Detection/coco_tfrecords/train'\n",
    "\n",
    "# Need to provide\n",
    "  # 1. image_dir: where images are present\n",
    "  # 2. object_annotations_file: where annotations are listed in json format\n",
    "  # 3. output_file_prefix: where to write output convered TFRecords files\n",
    "!python -m official.vision.data.create_coco_tf_record\\\n",
    "  --logtostderr \\\n",
    "  --image_dir={TRAIN_DATA_DIR} \\\n",
    "  --object_annotations_file={TRAIN_ANNOTATION_FILE_DIR} \\\n",
    "  --output_file_prefix={OUTPUT_TFRECORD_TRAIN} \\\n",
    "  --num_shards=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-29 08:18:56.300780: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-29 08:18:56.301066: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 08:18:56.306521: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 08:18:56.375729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 08:18:58.659725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-29 08:19:01.179847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-29 08:19:01.228735: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "I0429 08:19:01.229135 123998438500160 create_coco_tf_record.py:502] writing to output path: ./dataset/Object_Detection/coco_tfrecords/valid\n",
      "I0429 08:19:01.272755 123998438500160 create_coco_tf_record.py:374] Building bounding box index.\n",
      "I0429 08:19:01.275192 123998438500160 create_coco_tf_record.py:385] 1 images are missing bboxes.\n",
      "I0429 08:19:01.916398 123998438500160 tfrecord_lib.py:168] On image 0\n",
      "I0429 08:19:01.964280 123998438500160 tfrecord_lib.py:168] On image 100\n",
      "I0429 08:19:02.016995 123998438500160 tfrecord_lib.py:168] On image 200\n",
      "I0429 08:19:02.047749 123998438500160 tfrecord_lib.py:180] Finished writing, skipped 0 annotations.\n",
      "I0429 08:19:02.049484 123998438500160 create_coco_tf_record.py:537] Finished writing, skipped 0 annotations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VALID_DATA_DIR='./dataset/Object_Detection/coco/valid'\n",
    "VALID_ANNOTATION_FILE_DIR='./dataset/Object_Detection/coco/valid/valid_annotations.json'\n",
    "OUTPUT_TFRECORD_VALID='./dataset/Object_Detection/coco_tfrecords/valid'\n",
    "\n",
    "!python -m official.vision.data.create_coco_tf_record --logtostderr \\\n",
    "  --image_dir=$VALID_DATA_DIR \\\n",
    "  --object_annotations_file=$VALID_ANNOTATION_FILE_DIR \\\n",
    "  --output_file_prefix=$OUTPUT_TFRECORD_VALID \\\n",
    "  --num_shards=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-29 08:20:14.521282: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-29 08:20:14.522450: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 08:20:14.537077: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 08:20:14.587183: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 08:20:16.486583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-29 08:20:19.330134: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-29 08:20:19.361269: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "I0429 08:20:19.363236 126123451410240 create_coco_tf_record.py:502] writing to output path: ./dataset/Object_Detection/coco_tfrecords/test\n",
      "I0429 08:20:19.403976 126123451410240 create_coco_tf_record.py:374] Building bounding box index.\n",
      "I0429 08:20:19.404428 126123451410240 create_coco_tf_record.py:385] 0 images are missing bboxes.\n",
      "I0429 08:20:20.024098 126123451410240 tfrecord_lib.py:168] On image 0\n",
      "I0429 08:20:20.091973 126123451410240 tfrecord_lib.py:168] On image 100\n",
      "I0429 08:20:20.151532 126123451410240 tfrecord_lib.py:168] On image 200\n",
      "I0429 08:20:20.200955 126123451410240 tfrecord_lib.py:180] Finished writing, skipped 0 annotations.\n",
      "I0429 08:20:20.202189 126123451410240 create_coco_tf_record.py:537] Finished writing, skipped 0 annotations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TEST_DATA_DIR='./dataset/Object_Detection/coco/test'\n",
    "TEST_ANNOTATION_FILE_DIR='./dataset/Object_Detection/coco/test/test_annotations.json'\n",
    "OUTPUT_TFRECORD_TEST='./dataset/Object_Detection/coco_tfrecords/test'\n",
    "\n",
    "!python -m official.vision.data.create_coco_tf_record \\\n",
    "    --logtostderr \\\n",
    "    --image_dir=$TEST_DATA_DIR \\\n",
    "    --object_annotations_file=$TEST_ANNOTATION_FILE_DIR \\\n",
    "    --output_file_prefix=$OUTPUT_TFRECORD_TEST \\\n",
    "    --num_shards=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_input_path = (\n",
    "    \"./dataset/Object_Detection/coco_tfrecords/train-00000-of-00001.tfrecord\"\n",
    ")\n",
    "valid_data_input_path = (\n",
    "    \"./dataset/Object_Detection/coco_tfrecords/valid-00000-of-00001.tfrecord\"\n",
    ")\n",
    "test_data_input_path = (\n",
    "    \"./dataset/Object_Detection/coco_tfrecords/test-00000-of-00001.tfrecord\"\n",
    ")\n",
    "model_dir = \"./trained_model/\"\n",
    "export_dir = \"./model/\"\n",
    "\n",
    "exp_config = exp_factory.get_exp_config(\"fasterrcnn_resnetfpn_coco\")\n",
    "\n",
    "batch_size = 8\n",
    "num_classes = 5\n",
    "\n",
    "#\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "IMG_SIZE = [HEIGHT, WIDTH, 3]\n",
    "\n",
    "# Backbone config.\n",
    "exp_config.task.freeze_backbone = False\n",
    "exp_config.task.annotation_file = \"\"\n",
    "\n",
    "# Model config.\n",
    "exp_config.task.model.input_size = IMG_SIZE\n",
    "exp_config.task.model.num_classes = num_classes + 1\n",
    "# exp_config.task.model.detection_generator.tflite_post_processing.max_classes_per_detection = (\n",
    "#     exp_config.task.model.num_classes\n",
    "# )\n",
    "\n",
    "# Training data config.\n",
    "exp_config.task.train_data.input_path = train_data_input_path\n",
    "exp_config.task.train_data.dtype = \"float32\"\n",
    "exp_config.task.train_data.global_batch_size = batch_size\n",
    "exp_config.task.train_data.parser.aug_scale_max = 1.0\n",
    "exp_config.task.train_data.parser.aug_scale_min = 1.0\n",
    "\n",
    "# Validation data config.\n",
    "exp_config.task.validation_data.input_path = valid_data_input_path\n",
    "exp_config.task.validation_data.dtype = \"float32\"\n",
    "exp_config.task.validation_data.global_batch_size = batch_size\n",
    "\n",
    "\n",
    "device = 'CPU'\n",
    "\n",
    "train_steps = 1000\n",
    "exp_config.trainer.steps_per_loop = (\n",
    "    100  # steps_per_loop = num_of_training_examples // train_batch_size\n",
    ")\n",
    "\n",
    "exp_config.trainer.summary_interval = 100\n",
    "exp_config.trainer.checkpoint_interval = 100\n",
    "exp_config.trainer.validation_interval = 100\n",
    "exp_config.trainer.validation_steps = (\n",
    "    100  # validation_steps = num_of_validation_examples // eval_batch_size\n",
    ")\n",
    "exp_config.trainer.train_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_steps = 100\n",
    "# exp_config.trainer.optimizer_config.learning_rate.type = \"cosine\"\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.1\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentConfig(task=MaskRCNNTask(init_checkpoint='gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet/ckpt-28080',\n",
      "                                   model=MaskRCNN(num_classes=6,\n",
      "                                                  input_size=[256, 256, 3],\n",
      "                                                  min_level=2,\n",
      "                                                  max_level=6,\n",
      "                                                  anchor=Anchor(num_scales=1,\n",
      "                                                                aspect_ratios=[0.5,\n",
      "                                                                               1.0,\n",
      "                                                                               2.0],\n",
      "                                                                anchor_size=8.0),\n",
      "                                                  include_mask=False,\n",
      "                                                  outer_boxes_scale=1.0,\n",
      "                                                  backbone=Backbone(type='resnet',\n",
      "                                                                    resnet=ResNet(model_id=50,\n",
      "                                                                                  depth_multiplier=1.0,\n",
      "                                                                                  stem_type='v0',\n",
      "                                                                                  se_ratio=0.0,\n",
      "                                                                                  stochastic_depth_drop_rate=0.0,\n",
      "                                                                                  scale_stem=True,\n",
      "                                                                                  resnetd_shortcut=False,\n",
      "                                                                                  replace_stem_max_pool=False,\n",
      "                                                                                  bn_trainable=True),\n",
      "                                                                    dilated_resnet=DilatedResNet(model_id=50,\n",
      "                                                                                                 output_stride=16,\n",
      "                                                                                                 multigrid=None,\n",
      "                                                                                                 stem_type='v0',\n",
      "                                                                                                 last_stage_repeats=1,\n",
      "                                                                                                 se_ratio=0.0,\n",
      "                                                                                                 stochastic_depth_drop_rate=0.0,\n",
      "                                                                                                 resnetd_shortcut=False,\n",
      "                                                                                                 replace_stem_max_pool=False),\n",
      "                                                                    revnet=RevNet(model_id=56),\n",
      "                                                                    efficientnet=EfficientNet(model_id='b0',\n",
      "                                                                                              se_ratio=0.0,\n",
      "                                                                                              stochastic_depth_drop_rate=0.0),\n",
      "                                                                    spinenet=SpineNet(model_id='49',\n",
      "                                                                                      stochastic_depth_drop_rate=0.0,\n",
      "                                                                                      min_level=3,\n",
      "                                                                                      max_level=7),\n",
      "                                                                    spinenet_mobile=SpineNetMobile(model_id='49',\n",
      "                                                                                                   stochastic_depth_drop_rate=0.0,\n",
      "                                                                                                   se_ratio=0.2,\n",
      "                                                                                                   expand_ratio=6,\n",
      "                                                                                                   min_level=3,\n",
      "                                                                                                   max_level=7,\n",
      "                                                                                                   use_keras_upsampling_2d=False),\n",
      "                                                                    mobilenet=MobileNet(model_id='MobileNetV2',\n",
      "                                                                                        filter_size_scale=1.0,\n",
      "                                                                                        stochastic_depth_drop_rate=0.0,\n",
      "                                                                                        output_stride=None,\n",
      "                                                                                        output_intermediate_endpoints=False),\n",
      "                                                                    mobiledet=MobileDet(model_id='MobileDetCPU',\n",
      "                                                                                        filter_size_scale=1.0),\n",
      "                                                                    vit=VisionTransformer(model_name='vit-b16',\n",
      "                                                                                          pooler='token',\n",
      "                                                                                          representation_size=0,\n",
      "                                                                                          hidden_size=1,\n",
      "                                                                                          patch_size=16,\n",
      "                                                                                          transformer=Transformer(mlp_dim=1,\n",
      "                                                                                                                  num_heads=1,\n",
      "                                                                                                                  num_layers=1,\n",
      "                                                                                                                  attention_dropout_rate=0.0,\n",
      "                                                                                                                  dropout_rate=0.0),\n",
      "                                                                                          init_stochastic_depth_rate=0.0,\n",
      "                                                                                          original_init=True,\n",
      "                                                                                          pos_embed_shape=None,\n",
      "                                                                                          output_encoded_tokens=True,\n",
      "                                                                                          output_2d_feature_maps=False,\n",
      "                                                                                          layer_scale_init_value=0.0,\n",
      "                                                                                          transformer_partition_dims=None)),\n",
      "                                                  decoder=Decoder(type='fpn',\n",
      "                                                                  fpn=FPN(num_filters=256,\n",
      "                                                                          fusion_type='sum',\n",
      "                                                                          use_separable_conv=False,\n",
      "                                                                          use_keras_layer=False),\n",
      "                                                                  nasfpn=NASFPN(num_filters=256,\n",
      "                                                                                num_repeats=5,\n",
      "                                                                                use_separable_conv=False),\n",
      "                                                                  identity=Identity(),\n",
      "                                                                  aspp=ASPP(level=4,\n",
      "                                                                            dilation_rates=[],\n",
      "                                                                            dropout_rate=0.0,\n",
      "                                                                            num_filters=256,\n",
      "                                                                            use_depthwise_convolution=False,\n",
      "                                                                            pool_kernel_size=None,\n",
      "                                                                            spp_layer_version='v1',\n",
      "                                                                            output_tensor=False)),\n",
      "                                                  rpn_head=RPNHead(num_convs=1,\n",
      "                                                                   num_filters=256,\n",
      "                                                                   use_separable_conv=False),\n",
      "                                                  detection_head=DetectionHead(num_convs=4,\n",
      "                                                                               num_filters=256,\n",
      "                                                                               use_separable_conv=False,\n",
      "                                                                               num_fcs=1,\n",
      "                                                                               fc_dims=1024,\n",
      "                                                                               class_agnostic_bbox_pred=False,\n",
      "                                                                               cascade_class_ensemble=False),\n",
      "                                                  roi_generator=ROIGenerator(pre_nms_top_k=2000,\n",
      "                                                                             pre_nms_score_threshold=0.0,\n",
      "                                                                             pre_nms_min_size_threshold=0.0,\n",
      "                                                                             nms_iou_threshold=0.7,\n",
      "                                                                             num_proposals=1000,\n",
      "                                                                             test_pre_nms_top_k=1000,\n",
      "                                                                             test_pre_nms_score_threshold=0.0,\n",
      "                                                                             test_pre_nms_min_size_threshold=0.0,\n",
      "                                                                             test_nms_iou_threshold=0.7,\n",
      "                                                                             test_num_proposals=1000,\n",
      "                                                                             use_batched_nms=False),\n",
      "                                                  roi_sampler=ROISampler(mix_gt_boxes=True,\n",
      "                                                                         num_sampled_rois=512,\n",
      "                                                                         foreground_fraction=0.25,\n",
      "                                                                         foreground_iou_threshold=0.5,\n",
      "                                                                         background_iou_high_threshold=0.5,\n",
      "                                                                         background_iou_low_threshold=0.0,\n",
      "                                                                         cascade_iou_thresholds=None),\n",
      "                                                  roi_aligner=ROIAligner(crop_size=7,\n",
      "                                                                         sample_offset=0.5),\n",
      "                                                  detection_generator=DetectionGenerator(apply_nms=True,\n",
      "                                                                                         pre_nms_top_k=5000,\n",
      "                                                                                         pre_nms_score_threshold=0.05,\n",
      "                                                                                         nms_iou_threshold=0.5,\n",
      "                                                                                         max_num_detections=100,\n",
      "                                                                                         nms_version='v2',\n",
      "                                                                                         use_cpu_nms=False,\n",
      "                                                                                         soft_nms_sigma=None,\n",
      "                                                                                         use_sigmoid_probability=False),\n",
      "                                                  mask_head=None,\n",
      "                                                  mask_sampler=None,\n",
      "                                                  mask_roi_aligner=None,\n",
      "                                                  norm_activation=NormActivation(activation='relu',\n",
      "                                                                                 use_sync_bn=True,\n",
      "                                                                                 norm_momentum=0.997,\n",
      "                                                                                 norm_epsilon=0.0001)),\n",
      "                                   train_data=DataConfig(input_path='./dataset/Object_Detection/coco_tfrecords/train-00000-of-00001.tfrecord',\n",
      "                                                         tfds_name='',\n",
      "                                                         tfds_split='',\n",
      "                                                         global_batch_size=8,\n",
      "                                                         is_training=True,\n",
      "                                                         drop_remainder=True,\n",
      "                                                         shuffle_buffer_size=10000,\n",
      "                                                         cache=False,\n",
      "                                                         cycle_length=None,\n",
      "                                                         block_length=1,\n",
      "                                                         ram_budget=None,\n",
      "                                                         deterministic=None,\n",
      "                                                         sharding=True,\n",
      "                                                         enable_tf_data_service=False,\n",
      "                                                         tf_data_service_address=None,\n",
      "                                                         tf_data_service_job_name=None,\n",
      "                                                         tfds_data_dir='',\n",
      "                                                         tfds_as_supervised=False,\n",
      "                                                         tfds_skip_decoding_feature='',\n",
      "                                                         enable_shared_tf_data_service_between_parallel_trainers=False,\n",
      "                                                         apply_tf_data_service_before_batching=False,\n",
      "                                                         trainer_id=None,\n",
      "                                                         seed=None,\n",
      "                                                         prefetch_buffer_size=None,\n",
      "                                                         autotune_algorithm=None,\n",
      "                                                         weights=None,\n",
      "                                                         dtype='float32',\n",
      "                                                         decoder=DataDecoder(type='simple_decoder',\n",
      "                                                                             simple_decoder=TfExampleDecoder(regenerate_source_id=False,\n",
      "                                                                                                             mask_binarize_threshold=None,\n",
      "                                                                                                             attribute_names=[]),\n",
      "                                                                             label_map_decoder=TfExampleDecoderLabelMap(regenerate_source_id=False,\n",
      "                                                                                                                        mask_binarize_threshold=None,\n",
      "                                                                                                                        label_map='')),\n",
      "                                                         parser=Parser(num_channels=3,\n",
      "                                                                       match_threshold=0.5,\n",
      "                                                                       unmatched_threshold=0.5,\n",
      "                                                                       aug_rand_hflip=True,\n",
      "                                                                       aug_rand_vflip=False,\n",
      "                                                                       aug_scale_min=1.0,\n",
      "                                                                       aug_scale_max=1.0,\n",
      "                                                                       aug_type=None,\n",
      "                                                                       skip_crowd_during_training=True,\n",
      "                                                                       max_num_instances=100,\n",
      "                                                                       rpn_match_threshold=0.7,\n",
      "                                                                       rpn_unmatched_threshold=0.3,\n",
      "                                                                       rpn_batch_size_per_im=256,\n",
      "                                                                       rpn_fg_fraction=0.5,\n",
      "                                                                       mask_crop_size=112,\n",
      "                                                                       pad=True,\n",
      "                                                                       keep_aspect_ratio=True),\n",
      "                                                         file_type='tfrecord',\n",
      "                                                         num_examples=-1),\n",
      "                                   validation_data=DataConfig(input_path='./dataset/Object_Detection/coco_tfrecords/valid-00000-of-00001.tfrecord',\n",
      "                                                              tfds_name='',\n",
      "                                                              tfds_split='',\n",
      "                                                              global_batch_size=8,\n",
      "                                                              is_training=False,\n",
      "                                                              drop_remainder=False,\n",
      "                                                              shuffle_buffer_size=10000,\n",
      "                                                              cache=False,\n",
      "                                                              cycle_length=None,\n",
      "                                                              block_length=1,\n",
      "                                                              ram_budget=None,\n",
      "                                                              deterministic=None,\n",
      "                                                              sharding=True,\n",
      "                                                              enable_tf_data_service=False,\n",
      "                                                              tf_data_service_address=None,\n",
      "                                                              tf_data_service_job_name=None,\n",
      "                                                              tfds_data_dir='',\n",
      "                                                              tfds_as_supervised=False,\n",
      "                                                              tfds_skip_decoding_feature='',\n",
      "                                                              enable_shared_tf_data_service_between_parallel_trainers=False,\n",
      "                                                              apply_tf_data_service_before_batching=False,\n",
      "                                                              trainer_id=None,\n",
      "                                                              seed=None,\n",
      "                                                              prefetch_buffer_size=None,\n",
      "                                                              autotune_algorithm=None,\n",
      "                                                              weights=None,\n",
      "                                                              dtype='float32',\n",
      "                                                              decoder=DataDecoder(type='simple_decoder',\n",
      "                                                                                  simple_decoder=TfExampleDecoder(regenerate_source_id=False,\n",
      "                                                                                                                  mask_binarize_threshold=None,\n",
      "                                                                                                                  attribute_names=[]),\n",
      "                                                                                  label_map_decoder=TfExampleDecoderLabelMap(regenerate_source_id=False,\n",
      "                                                                                                                             mask_binarize_threshold=None,\n",
      "                                                                                                                             label_map='')),\n",
      "                                                              parser=Parser(num_channels=3,\n",
      "                                                                            match_threshold=0.5,\n",
      "                                                                            unmatched_threshold=0.5,\n",
      "                                                                            aug_rand_hflip=False,\n",
      "                                                                            aug_rand_vflip=False,\n",
      "                                                                            aug_scale_min=1.0,\n",
      "                                                                            aug_scale_max=1.0,\n",
      "                                                                            aug_type=None,\n",
      "                                                                            skip_crowd_during_training=True,\n",
      "                                                                            max_num_instances=100,\n",
      "                                                                            rpn_match_threshold=0.7,\n",
      "                                                                            rpn_unmatched_threshold=0.3,\n",
      "                                                                            rpn_batch_size_per_im=256,\n",
      "                                                                            rpn_fg_fraction=0.5,\n",
      "                                                                            mask_crop_size=112,\n",
      "                                                                            pad=True,\n",
      "                                                                            keep_aspect_ratio=True),\n",
      "                                                              file_type='tfrecord',\n",
      "                                                              num_examples=-1),\n",
      "                                   name=None,\n",
      "                                   differential_privacy_config=None,\n",
      "                                   allow_image_summary=False,\n",
      "                                   losses=Losses(loss_weight=1.0,\n",
      "                                                 rpn_huber_loss_delta=0.1111111111111111,\n",
      "                                                 frcnn_huber_loss_delta=1.0,\n",
      "                                                 frcnn_class_use_binary_cross_entropy=False,\n",
      "                                                 frcnn_class_loss_top_k_percent=1.0,\n",
      "                                                 l2_weight_decay=4e-05,\n",
      "                                                 rpn_score_weight=1.0,\n",
      "                                                 rpn_box_weight=1.0,\n",
      "                                                 frcnn_class_weight=1.0,\n",
      "                                                 frcnn_box_weight=1.0,\n",
      "                                                 mask_weight=1.0,\n",
      "                                                 class_weights=None),\n",
      "                                   init_checkpoint_modules='backbone',\n",
      "                                   annotation_file='',\n",
      "                                   per_category_metrics=False,\n",
      "                                   allowed_mask_class_ids=None,\n",
      "                                   use_coco_metrics=True,\n",
      "                                   use_wod_metrics=False,\n",
      "                                   use_approx_instance_metrics=False,\n",
      "                                   freeze_backbone=False),\n",
      "                 trainer=TrainerConfig(optimizer_config=OptimizationConfig(optimizer=OptimizerConfig(type='sgd',\n",
      "                                                                                                     sgd=SGDConfig(clipnorm=None,\n",
      "                                                                                                                   clipvalue=None,\n",
      "                                                                                                                   global_clipnorm=None,\n",
      "                                                                                                                   name='SGD',\n",
      "                                                                                                                   decay=0.0,\n",
      "                                                                                                                   nesterov=False,\n",
      "                                                                                                                   momentum=0.9),\n",
      "                                                                                                     sgd_experimental=SGDExperimentalConfig(clipnorm=None,\n",
      "                                                                                                                                            clipvalue=None,\n",
      "                                                                                                                                            global_clipnorm=None,\n",
      "                                                                                                                                            name='SGD',\n",
      "                                                                                                                                            nesterov=False,\n",
      "                                                                                                                                            momentum=0.0,\n",
      "                                                                                                                                            jit_compile=False),\n",
      "                                                                                                     adam=AdamConfig(clipnorm=None,\n",
      "                                                                                                                     clipvalue=None,\n",
      "                                                                                                                     global_clipnorm=None,\n",
      "                                                                                                                     name='Adam',\n",
      "                                                                                                                     beta_1=0.9,\n",
      "                                                                                                                     beta_2=0.999,\n",
      "                                                                                                                     epsilon=1e-07,\n",
      "                                                                                                                     amsgrad=False),\n",
      "                                                                                                     adam_experimental=AdamExperimentalConfig(clipnorm=None,\n",
      "                                                                                                                                              clipvalue=None,\n",
      "                                                                                                                                              global_clipnorm=None,\n",
      "                                                                                                                                              name='Adam',\n",
      "                                                                                                                                              beta_1=0.9,\n",
      "                                                                                                                                              beta_2=0.999,\n",
      "                                                                                                                                              epsilon=1e-07,\n",
      "                                                                                                                                              amsgrad=False,\n",
      "                                                                                                                                              jit_compile=False),\n",
      "                                                                                                     adamw=AdamWeightDecayConfig(clipnorm=None,\n",
      "                                                                                                                                 clipvalue=None,\n",
      "                                                                                                                                 global_clipnorm=None,\n",
      "                                                                                                                                 name='AdamWeightDecay',\n",
      "                                                                                                                                 beta_1=0.9,\n",
      "                                                                                                                                 beta_2=0.999,\n",
      "                                                                                                                                 epsilon=1e-07,\n",
      "                                                                                                                                 amsgrad=False,\n",
      "                                                                                                                                 weight_decay_rate=0.0,\n",
      "                                                                                                                                 include_in_weight_decay=None,\n",
      "                                                                                                                                 exclude_from_weight_decay=None,\n",
      "                                                                                                                                 gradient_clip_norm=1.0),\n",
      "                                                                                                     adamw_experimental=AdamWeightDecayExperimentalConfig(clipnorm=None,\n",
      "                                                                                                                                                          clipvalue=None,\n",
      "                                                                                                                                                          global_clipnorm=1.0,\n",
      "                                                                                                                                                          name='AdamWeightDecayExperimental',\n",
      "                                                                                                                                                          beta_1=0.9,\n",
      "                                                                                                                                                          beta_2=0.999,\n",
      "                                                                                                                                                          epsilon=1e-07,\n",
      "                                                                                                                                                          amsgrad=False,\n",
      "                                                                                                                                                          weight_decay=0.0,\n",
      "                                                                                                                                                          jit_compile=False),\n",
      "                                                                                                     lamb=LAMBConfig(clipnorm=None,\n",
      "                                                                                                                     clipvalue=None,\n",
      "                                                                                                                     global_clipnorm=None,\n",
      "                                                                                                                     name='LAMB',\n",
      "                                                                                                                     beta_1=0.9,\n",
      "                                                                                                                     beta_2=0.999,\n",
      "                                                                                                                     epsilon=1e-06,\n",
      "                                                                                                                     weight_decay_rate=0.0,\n",
      "                                                                                                                     exclude_from_weight_decay=None,\n",
      "                                                                                                                     exclude_from_layer_adaptation=None),\n",
      "                                                                                                     rmsprop=RMSPropConfig(clipnorm=None,\n",
      "                                                                                                                           clipvalue=None,\n",
      "                                                                                                                           global_clipnorm=None,\n",
      "                                                                                                                           name='RMSprop',\n",
      "                                                                                                                           rho=0.9,\n",
      "                                                                                                                           momentum=0.0,\n",
      "                                                                                                                           epsilon=1e-07,\n",
      "                                                                                                                           centered=False),\n",
      "                                                                                                     lars=LARSConfig(clipnorm=None,\n",
      "                                                                                                                     clipvalue=None,\n",
      "                                                                                                                     global_clipnorm=None,\n",
      "                                                                                                                     name='LARS',\n",
      "                                                                                                                     momentum=0.9,\n",
      "                                                                                                                     eeta=0.001,\n",
      "                                                                                                                     weight_decay_rate=0.0,\n",
      "                                                                                                                     nesterov=False,\n",
      "                                                                                                                     classic_momentum=True,\n",
      "                                                                                                                     exclude_from_weight_decay=None,\n",
      "                                                                                                                     exclude_from_layer_adaptation=None),\n",
      "                                                                                                     adagrad=AdagradConfig(clipnorm=None,\n",
      "                                                                                                                           clipvalue=None,\n",
      "                                                                                                                           global_clipnorm=None,\n",
      "                                                                                                                           name='Adagrad',\n",
      "                                                                                                                           initial_accumulator_value=0.1,\n",
      "                                                                                                                           epsilon=1e-07),\n",
      "                                                                                                     slide=SLIDEConfig(clipnorm=None,\n",
      "                                                                                                                       clipvalue=None,\n",
      "                                                                                                                       global_clipnorm=None,\n",
      "                                                                                                                       name='SLIDE',\n",
      "                                                                                                                       beta_1=0.9,\n",
      "                                                                                                                       beta_2=0.999,\n",
      "                                                                                                                       epsilon=1e-06,\n",
      "                                                                                                                       weight_decay_rate=0.0,\n",
      "                                                                                                                       weight_decay_type='inner',\n",
      "                                                                                                                       exclude_from_weight_decay=None,\n",
      "                                                                                                                       exclude_from_layer_adaptation=None,\n",
      "                                                                                                                       include_in_sparse_layer_adaptation=None,\n",
      "                                                                                                                       sparse_layer_learning_rate=0.1,\n",
      "                                                                                                                       do_gradient_rescaling=True,\n",
      "                                                                                                                       norm_type='layer',\n",
      "                                                                                                                       ratio_clip_norm=100000.0),\n",
      "                                                                                                     adafactor=AdafactorConfig(clipnorm=None,\n",
      "                                                                                                                               clipvalue=None,\n",
      "                                                                                                                               global_clipnorm=None,\n",
      "                                                                                                                               name='Adafactor',\n",
      "                                                                                                                               factored=True,\n",
      "                                                                                                                               multiply_by_parameter_scale=True,\n",
      "                                                                                                                               beta1=None,\n",
      "                                                                                                                               decay_rate=0.8,\n",
      "                                                                                                                               step_offset=0,\n",
      "                                                                                                                               clipping_threshold=1.0,\n",
      "                                                                                                                               min_dim_size_to_factor=128,\n",
      "                                                                                                                               epsilon1=1e-30,\n",
      "                                                                                                                               epsilon2=0.001,\n",
      "                                                                                                                               weight_decay=None,\n",
      "                                                                                                                               include_in_weight_decay=None),\n",
      "                                                                                                     adafactor_keras=AdafactorKerasConfig(clipnorm=None,\n",
      "                                                                                                                                          clipvalue=None,\n",
      "                                                                                                                                          global_clipnorm=None,\n",
      "                                                                                                                                          name='Adafactor',\n",
      "                                                                                                                                          learning_rate=0.001,\n",
      "                                                                                                                                          beta_2_decay=-0.8,\n",
      "                                                                                                                                          epsilon_1=1e-30,\n",
      "                                                                                                                                          epsilon_2=0.001,\n",
      "                                                                                                                                          clip_threshold=1.0,\n",
      "                                                                                                                                          relative_step=True)),\n",
      "                                                                           ema=None,\n",
      "                                                                           learning_rate=LrConfig(type='cosine',\n",
      "                                                                                                  constant=ConstantLrConfig(name='Constant',\n",
      "                                                                                                                            learning_rate=0.1),\n",
      "                                                                                                  stepwise=StepwiseLrConfig(name='PiecewiseConstantDecay',\n",
      "                                                                                                                            boundaries=[15000,\n",
      "                                                                                                                                        20000],\n",
      "                                                                                                                            values=[0.12,\n",
      "                                                                                                                                    0.012,\n",
      "                                                                                                                                    0.0012],\n",
      "                                                                                                                            offset=0),\n",
      "                                                                                                  exponential=ExponentialLrConfig(name='ExponentialDecay',\n",
      "                                                                                                                                  initial_learning_rate=None,\n",
      "                                                                                                                                  decay_steps=None,\n",
      "                                                                                                                                  decay_rate=None,\n",
      "                                                                                                                                  staircase=None,\n",
      "                                                                                                                                  offset=0),\n",
      "                                                                                                  polynomial=PolynomialLrConfig(name='PolynomialDecay',\n",
      "                                                                                                                                initial_learning_rate=None,\n",
      "                                                                                                                                decay_steps=None,\n",
      "                                                                                                                                end_learning_rate=0.0001,\n",
      "                                                                                                                                power=1.0,\n",
      "                                                                                                                                cycle=False,\n",
      "                                                                                                                                offset=0),\n",
      "                                                                                                  cosine=CosineLrConfig(name='CosineDecay',\n",
      "                                                                                                                        initial_learning_rate=0.1,\n",
      "                                                                                                                        decay_steps=1000,\n",
      "                                                                                                                        alpha=0.0,\n",
      "                                                                                                                        offset=0),\n",
      "                                                                                                  power=DirectPowerLrConfig(name='DirectPowerDecay',\n",
      "                                                                                                                            initial_learning_rate=None,\n",
      "                                                                                                                            power=-0.5),\n",
      "                                                                                                  power_linear=PowerAndLinearDecayLrConfig(name='PowerAndLinearDecay',\n",
      "                                                                                                                                           initial_learning_rate=None,\n",
      "                                                                                                                                           total_decay_steps=None,\n",
      "                                                                                                                                           power=-0.5,\n",
      "                                                                                                                                           linear_decay_fraction=0.1,\n",
      "                                                                                                                                           offset=0),\n",
      "                                                                                                  power_with_offset=PowerDecayWithOffsetLrConfig(name='PowerDecayWithOffset',\n",
      "                                                                                                                                                 initial_learning_rate=None,\n",
      "                                                                                                                                                 power=-0.5,\n",
      "                                                                                                                                                 offset=0,\n",
      "                                                                                                                                                 pre_offset_learning_rate=1000000.0),\n",
      "                                                                                                  step_cosine_with_offset=StepCosineLrConfig(name='StepCosineDecayWithOffset',\n",
      "                                                                                                                                             boundaries=None,\n",
      "                                                                                                                                             values=None,\n",
      "                                                                                                                                             offset=0)),\n",
      "                                                                           warmup=WarmupConfig(type='linear',\n",
      "                                                                                               linear=LinearWarmupConfig(name='linear',\n",
      "                                                                                                                         warmup_learning_rate=0.05,\n",
      "                                                                                                                         warmup_steps=100),\n",
      "                                                                                               polynomial=PolynomialWarmupConfig(name='polynomial',\n",
      "                                                                                                                                 power=1,\n",
      "                                                                                                                                 warmup_steps=None))),\n",
      "                                       train_tf_while_loop=True,\n",
      "                                       train_tf_function=True,\n",
      "                                       eval_tf_function=True,\n",
      "                                       eval_tf_while_loop=False,\n",
      "                                       allow_tpu_summary=False,\n",
      "                                       steps_per_loop=100,\n",
      "                                       summary_interval=100,\n",
      "                                       checkpoint_interval=100,\n",
      "                                       max_to_keep=5,\n",
      "                                       continuous_eval_timeout=3600,\n",
      "                                       train_steps=1000,\n",
      "                                       validation_steps=100,\n",
      "                                       validation_interval=100,\n",
      "                                       best_checkpoint_export_subdir='',\n",
      "                                       best_checkpoint_eval_metric='',\n",
      "                                       best_checkpoint_metric_comp='higher',\n",
      "                                       loss_upper_bound=1000000.0,\n",
      "                                       recovery_begin_steps=0,\n",
      "                                       recovery_max_trials=0,\n",
      "                                       validation_summary_subdir='validation',\n",
      "                                       preemption_on_demand_checkpoint=True),\n",
      "                 runtime=RuntimeConfig(distribution_strategy='mirrored',\n",
      "                                       enable_xla=False,\n",
      "                                       gpu_thread_mode=None,\n",
      "                                       dataset_num_private_threads=None,\n",
      "                                       per_gpu_thread_count=0,\n",
      "                                       tpu=None,\n",
      "                                       num_gpus=0,\n",
      "                                       worker_hosts=None,\n",
      "                                       task_index=-1,\n",
      "                                       all_reduce_alg=None,\n",
      "                                       num_packs=1,\n",
      "                                       mixed_precision_dtype='bfloat16',\n",
      "                                       loss_scale=None,\n",
      "                                       run_eagerly=False,\n",
      "                                       batchnorm_spatial_persistent=False,\n",
      "                                       tpu_enable_xla_dynamic_padder=None,\n",
      "                                       num_cores_per_replica=1,\n",
      "                                       default_shard_dim=-1,\n",
      "                                       use_tpu_mp_strategy=False))\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU is slow, so only train for a few steps.\n",
      "Warning: this will be really slow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 09:39:45.003457: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-29 09:39:45.030372: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [\n",
    "    logical_device.name for logical_device in tf.config.list_logical_devices()\n",
    "]\n",
    "\n",
    "if \"GPU\" in \"\".join(logical_device_names):\n",
    "    print(\"This may be broken in Colab.\")\n",
    "    device = \"GPU\"\n",
    "elif \"TPU\" in \"\".join(logical_device_names):\n",
    "    print(\"This may be broken in Colab.\")\n",
    "    device = \"TPU\"\n",
    "else:\n",
    "    print(\"Running on CPU is slow, so only train for a few steps.\")\n",
    "    device = \"CPU\"\n",
    "\n",
    "if exp_config.runtime.mixed_precision_dtype == tf.float16:\n",
    "    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "if \"GPU\" in \"\".join(logical_device_names):\n",
    "    distribution_strategy = tf.distribute.MirroredStrategy()\n",
    "elif \"TPU\" in \"\".join(logical_device_names):\n",
    "    tf.tpu.experimental.initialize_tpu_system()\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"/device:TPU_SYSTEM:0\")\n",
    "    distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    print(\"Warning: this will be really slow.\")\n",
    "    distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "images.shape: (8, 256, 256, 3)  images.dtype: tf.float32\n",
      "labels.keys: dict_keys(['anchor_boxes', 'image_info', 'rpn_score_targets', 'rpn_box_targets', 'gt_boxes', 'gt_classes'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 09:47:03.739532: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in task.build_inputs(exp_config.task.train_data).take(1):\n",
    "    print()\n",
    "    print(f\"images.shape: {str(images.shape):16}  images.dtype: {images.dtype!r}\")\n",
    "    print(f\"labels.keys: {labels.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =  [\n",
    "    { \"id\": 1, \"name\": \"Ready\", },\n",
    "    { \"id\": 2, \"name\": \"empty_pod\", },\n",
    "    { \"id\": 3, \"name\": \"germination\", },\n",
    "    { \"id\": 4, \"name\": \"pod\", },\n",
    "    { \"id\": 5, \"name\": \"young\", }\n",
    "]\n",
    "\n",
    "category_index = dict()\n",
    "\n",
    "for item in categories:\n",
    "    category_index[ item['id'] ] = item\n",
    "\n",
    "tf_ex_decoder = TfExampleDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(raw_records, num_of_examples):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates = True\n",
    "    min_score_thresh = 0.30\n",
    "    for i, serialized_example in enumerate(raw_records):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "        image = decoded_tensors[\"image\"].numpy().astype(\"uint8\")\n",
    "        scores = np.ones(shape=(len(decoded_tensors[\"groundtruth_boxes\"])))\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            decoded_tensors[\"groundtruth_boxes\"].numpy(),\n",
    "            decoded_tensors[\"groundtruth_classes\"].numpy().astype(\"int\"),\n",
    "            scores,\n",
    "            category_index=category_index,\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            agnostic_mode=False,\n",
    "            instance_masks=None,\n",
    "            line_thickness=4,\n",
    "        )\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image-{i+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 09:56:37.322818: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "buffer_size = 20\n",
    "num_of_examples = 3\n",
    "\n",
    "raw_records = (\n",
    "    tf.data.TFRecordDataset(exp_config.task.train_data.input_path)\n",
    "    .shuffle(buffer_size=buffer_size)\n",
    "    .take(num_of_examples)\n",
    ")\n",
    "show_batch(raw_records, num_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring or initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 09:58:05.870548: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Customized initialization is done through the passed `init_fn`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Customized initialization is done through the passed `init_fn`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:      0 | training until step 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 09:58:31.928781: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2024-04-29 10:00:12.235087: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    }
   ],
   "source": [
    "model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "    distribution_strategy=distribution_strategy,\n",
    "    task=task,\n",
    "    mode=\"train_and_eval\",\n",
    "    params=exp_config,\n",
    "    model_dir=model_dir,\n",
    "    run_post_eval=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir './trained_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type=\"image_tensor\",\n",
    "    batch_size=1,\n",
    "    input_image_size=[HEIGHT, WIDTH],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(model_dir),\n",
    "    export_dir=export_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    image = None\n",
    "    if path.startswith(\"http\"):\n",
    "        response = urlopen(path)\n",
    "        image_data = response.read()\n",
    "        image_data = BytesIO(image_data)\n",
    "        image = Image.open(image_data)\n",
    "    else:\n",
    "        image_data = tf.io.gfile.GFile(path, \"rb\").read()\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "    (im_width, im_height) = image.size\n",
    "    return (\n",
    "        np.array(image.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)\n",
    "    )\n",
    "\n",
    "\n",
    "def build_inputs_for_object_detection(image, input_image_size):\n",
    "    \"\"\"Builds Object Detection model inputs for serving.\"\"\"\n",
    "    image, _ = resize_and_crop_image(\n",
    "        image,\n",
    "        input_image_size,\n",
    "        padded_size=input_image_size,\n",
    "        aug_scale_min=1.0,\n",
    "        aug_scale_max=1.0,\n",
    "    )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_examples = 3\n",
    "\n",
    "test_ds = tf.data.TFRecordDataset(\n",
    "    \"./bccd_coco_tfrecords/test-00000-of-00001.tfrecord\"\n",
    ").take(num_of_examples)\n",
    "show_batch(test_ds, num_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(export_dir)\n",
    "model_fn = imported.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_size = (HEIGHT, WIDTH)\n",
    "plt.figure(figsize=(20, 20))\n",
    "min_score_thresh = (\n",
    "    0.30  # Change minimum score for threshold to see all bounding boxes confidences.\n",
    ")\n",
    "\n",
    "for i, serialized_example in enumerate(test_ds):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "    image = build_inputs_for_object_detection(\n",
    "        decoded_tensors[\"image\"], input_image_size\n",
    "    )\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    image = tf.cast(image, dtype=tf.uint8)\n",
    "    image_np = image[0].numpy()\n",
    "    result = model_fn(image)\n",
    "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        result[\"detection_boxes\"][0].numpy(),\n",
    "        result[\"detection_classes\"][0].numpy().astype(int),\n",
    "        result[\"detection_scores\"][0].numpy(),\n",
    "        category_index=category_index,\n",
    "        use_normalized_coordinates=False,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=min_score_thresh,\n",
    "        agnostic_mode=False,\n",
    "        instance_masks=None,\n",
    "        line_thickness=4,\n",
    "    )\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uts-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
